{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "28bfee2d-4b98-46e4-9362-4bf00a5d436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h3\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely import geometry\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import PoissonRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, GroupKFold, GroupShuffleSplit, RandomizedSearchCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc8449c-be4a-4395-a760-71d1c2f06113",
   "metadata": {},
   "source": [
    "# 0. Data Read & Cleanup\n",
    "Here we'll read in the data, drop a bunch of unnecessary columns, and also rename some columns to have cleaner names."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa0f31c-6ae0-40ca-b930-35083d18c5d1",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "fa36a0b8-af3d-4673-b893-094f399181ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/dtypes/cast.py:118: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n",
      "  arr = construct_1d_object_array_from_listlike(values)\n"
     ]
    }
   ],
   "source": [
    "gcs_path = 'gs://smart4'\n",
    "\n",
    "count_data = pd.read_csv(f'{gcs_path}/count_file/Final_data_march18.csv')\n",
    "\n",
    "unwanted_columns = [\n",
    "    'Unnamed: 0',\n",
    "    'X', 'ID',\n",
    "    'ATT.in.Million',\n",
    "    'bgarea_t', 'bgcliparea_t', 'pctofbgarea_t',\n",
    "    'bgarea_q', 'bgcliparea_q', 'pctofbgarea_q',\n",
    "    'bgarea_h', 'bgcliparea_h', 'pctofbgarea_h',\n",
    "    'rt_i_shd_tot_width', 'lt_i_shd_tot_width',\n",
    "    'near_strava_id', \n",
    "    'ATT.in.Thousands',\n",
    "    'rowIndex', 'primary', 'secondary', 'tertiary', 'residential', 'trunk', 'secondary_link', 'unclassified',\n",
    "    'speed_0_25', 'speed_21_35', 'speed_greater_than_35',\n",
    "    'path', 'bike_lane',\n",
    "    'bike_route', 'cycle_track', 'trail', 'Interstate', 'Freeway', 'Principal_Arterial',\n",
    "    'Minor_Arterial', 'Major_Collector', 'Minor_Collector', 'Local'\n",
    "]\n",
    "count_data = count_data.drop(columns=unwanted_columns)\n",
    "\n",
    "count_data['centroid'] = count_data.apply(lambda x: geometry.Point(x['Long'], x['Lat']), axis=1)\n",
    "count_data = gpd.GeoDataFrame(count_data, geometry='centroid', crs=4326)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4684aa-d612-4af8-a9e8-dd1d5ef33106",
   "metadata": {},
   "source": [
    "## Data cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "8cdbd060-1feb-4dd4-881d-35fc053e8167",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_data = count_data.rename(columns={\n",
    "    'Stv_commute_adb': 'strava_commute_adb',\n",
    "    'Stv_leisure_adb': 'strava_leisure_adb',\n",
    "    'Stv_Ave_speed': 'strava_average_speed'})\n",
    "\n",
    "count_data['total_lanes'] = count_data['rt_lanes_amt'] + count_data['lt_lanes_amt']\n",
    "count_data['strava_leisure_pct'] = \\\n",
    "    count_data['strava_leisure_adb']/(count_data[['strava_leisure_adb', 'strava_commute_adb']].sum(axis=1))\n",
    "\n",
    "count_data['bike_facs'] = count_data['bike_facs'].replace(\n",
    "    {'Not Collected': 'Unknown', \n",
    "     'Class V': 'Unknown',\n",
    "     'Class VI': 'Unknown'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "24232d41-b022-41ac-a9e1-52d0497c50a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_data['bike_facs'] = count_data['bike_facs'].fillna('Unknown')\n",
    "count_data['fclass'] = count_data['fclass'].fillna('unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab16828-5e5e-482e-a55f-265285658bfb",
   "metadata": {},
   "source": [
    "## Make matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "e6940a50-8bef-4f84-a5d6-74e60dc1dc18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['location', 'Lat', 'Long', 'year', 'ATT', 'no_of_months_data_collected',\n",
       "       'type', 'AADB', 'matched_seg_id', 'segment_id', 'street_name', 'county',\n",
       "       'tdg_id', 'lrs_cal_id', 'bikes_proh', 'bike_facs', 'int_tdg_id',\n",
       "       'loc_id', 'seg_counter', 'fclass', 'tasas_ids', 'ataip_ids', 'fc_draft',\n",
       "       'speed', 'slope', 'empnum_density_t', 'pctwhite_t', 'totwhitepersqmi_t',\n",
       "       'pctbiketowork_t', 'totbiketoworkpersqmi_t', 'pctatleastbachelors_t',\n",
       "       'totatleastbachelorspersqmi_t', 'pctnoveh_t', 'totnovehpersqmi_t',\n",
       "       'popdensitysqmi_t', 'hshlddensitysqmi_t', 'pctwhite_q',\n",
       "       'totwhitepersqmi_q', 'pctbiketowork_q', 'totbiketoworkpersqmi_q',\n",
       "       'pctatleastbachelors_q', 'totatleastbachelorspersqmi_q', 'pctnoveh_q',\n",
       "       'totnovehpersqmi_q', 'popdensitysqmi_q', 'hshlddensitysqmi_q',\n",
       "       'pctwhite_h', 'totwhitepersqmi_h', 'pctbiketowork_h',\n",
       "       'totbiketoworkpersqmi_h', 'pctatleastbachelors_h',\n",
       "       'totatleastbachelorspersqmi_h', 'pctnoveh_h', 'totnovehpersqmi_h',\n",
       "       'popdensitysqmi_h', 'hshlddensitysqmi_h', 'geom_length', 'access_code',\n",
       "       'adt_amt', 'truck_adt_amt', 'rt_lanes_amt', 'lt_lanes_amt',\n",
       "       'rt_trav_way_width', 'rt_o_shd_tot_width', 'lt_trav_way_width',\n",
       "       'lt_o_shd_tot_width', 'empnum_density_q', 'empnum_density_h',\n",
       "       'near_univ_miles', 'near_large_univ_miles', 'eco_type', 'geometry',\n",
       "       'forward_trip_count', 'reverse_trip_count',\n",
       "       'forward_commute_trip_count', 'reverse_commute_trip_count',\n",
       "       'forward_leisure_trip_count', 'reverse_leisure_trip_count',\n",
       "       'forward_average_speed', 'reverse_average_speed', 'index', 'Leg',\n",
       "       'strava_commute_adb', 'strava_leisure_adb', 'strava_average_speed',\n",
       "       'centroid', 'total_lanes', 'strava_leisure_pct'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "945a62dc-fac2-492f-9451-1712552bb103",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_col_templates = [\n",
    "    'popdensitysqmi_{}', 'hshlddensitysqmi_{}',\n",
    "    'empnum_density_{}', 'pctwhite_{}', 'pctbiketowork_{}', 'pctatleastbachelors_{}', \n",
    "    'pctnoveh_{}']\n",
    "\n",
    "demographic_cols = []\n",
    "for distance in ('t', 'q', 'h'):\n",
    "    demographic_cols += [col.format(distance) for col in demographic_col_templates]\n",
    "    \n",
    "strava_cols = ['strava_commute_adb', 'strava_leisure_adb', 'strava_average_speed', 'strava_leisure_pct']\n",
    "\n",
    "\n",
    "y_col = 'AADB'\n",
    "x_cols = ['bike_facs', 'fclass', 'fc_draft', 'speed', 'slope', \n",
    "          # 'adt_amt', 'total_lanes', ## - these were included, but are almost entirely Null\n",
    "          'near_univ_miles', 'near_large_univ_miles'] + strava_cols + demographic_cols \n",
    "\n",
    "\n",
    "X = count_data[x_cols]\n",
    "y = count_data[y_col]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396e8ec8-5bc6-4572-8e86-5cc0ee325158",
   "metadata": {},
   "source": [
    "ADT and number of lanes are almost entirely missing data.\n",
    "\n",
    "Everything else likely makes sense to fill with 0s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "db44a61b-35fe-42a0-a228-9943d92765ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0f62ef-e7d8-40b2-abf5-8e996658175b",
   "metadata": {},
   "source": [
    "# 1. Set up train-test splits\n",
    "Here we're going to use a grouped train/test split, grouped based on the `h3` index at resolution 7. This is to try to prevent information leakage from locations that are spatially adjacent. It's not perfect, but it should help (other than in edge cases of counts right on either side of a grid cell line)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "23466ffc-60ed-479b-b3f9-7e754654dfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.2\n",
    "GROUPER_COL = 'h3_7'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "3836af60-9108-4077-9185-9680f2f0c3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_data['h3_7'] = count_data.apply(lambda x: h3.geo_to_h3(x['Lat'], x['Long'], 7), axis=1)\n",
    "count_data['h3_8'] = count_data.apply(lambda x: h3.geo_to_h3(x['Lat'], x['Long'], 8), axis=1)\n",
    "\n",
    "grouper = count_data[GROUPER_COL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "b9f3de22-6e13-463f-9af6-301065a6beaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indx, test_indx = next(GroupShuffleSplit(random_state=42,test_size=TEST_SIZE).split(X, y, grouper))\n",
    "\n",
    "X_train, X_test, y_train, y_test = X.loc[train_indx], X.loc[test_indx], y[train_indx], y[test_indx]\n",
    "\n",
    "grouper_train = count_data[GROUPER_COL][train_indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "7254da89-52d3-4ae8-8233-4ec4faffa7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set is 20.26% of sample\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test set is {len(test_indx)/(len(test_indx) + len(train_indx)) * 100 :.2f}% of sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09c7d20-e93c-431a-bad1-4f8c08eafb48",
   "metadata": {},
   "source": [
    "# 2. Model Fitting\n",
    "Now we'll start estimating models. First let's set up a container for storing results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "b65ec146-a669-4314-b730-48e8f578797a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = {}\n",
    "\n",
    "def evaluate_model(model, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test):\n",
    "    \n",
    "    results = {\n",
    "        'in_sample_rmse': mean_squared_error(y_train, model.predict(X_train), squared=False),\n",
    "        'out_sample_rmse': mean_squared_error(y_test, model.predict(X_test), squared=False),\n",
    "        'model': model\n",
    "    }\n",
    "    print(results)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07ac86c-2549-4c36-9085-663b202aafc8",
   "metadata": {},
   "source": [
    "Make a set of folds for doing cross-validation for hyperparam tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "7dc4264a-bbda-4b40-87d5-8286a1fbae82",
   "metadata": {},
   "outputs": [],
   "source": [
    "gkf = GroupKFold()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed85059b-1ecb-4118-ba85-f76b5e9ff0b6",
   "metadata": {},
   "source": [
    "## 2a. Dummy Model\n",
    "As usual, the first thing we'll do is set a baseline for model accuracy by estimating a no-skill model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "24104dbb-aca1-49a0-a988-695a23b47417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'in_sample_rmse': 276.74668661055586, 'out_sample_rmse': 272.6618123376978, 'model': DummyRegressor()}\n"
     ]
    }
   ],
   "source": [
    "dummy_model = DummyRegressor()\n",
    "dummy_model.fit(X_train, y_train)\n",
    "\n",
    "model_results['dummy'] = evaluate_model(dummy_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5313aff6-0f2e-4888-8e04-2be68bcea6ee",
   "metadata": {},
   "source": [
    "## 2b. Vanilla Poisson Regression\n",
    "Here we'll one-hot encode categoricals, standard scale everything else, and dump into a Poisson regression. We'll also tune the regularization on the Poisson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "cfbe60e8-6f58-466c-93a6-e3befff5f7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['bike_facs', 'fclass', 'fc_draft']\n",
    "categorical_drop_vals = ['Unknown', 'unknown', 1]\n",
    "\n",
    "numeric_cols = [col for col in X_train.columns if col not in categorical_cols]\n",
    "\n",
    "base_column_transformers = [\n",
    "    ('categoricals', OneHotEncoder(drop=categorical_drop_vals), categorical_cols),\n",
    "    ('standard_scale', StandardScaler(), numeric_cols)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "c78814cf-a7d9-499b-af36-2d084562b968",
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_poisson_model = Pipeline(\n",
    "    [\n",
    "        ('transform', ColumnTransformer(base_column_transformers,)),\n",
    "        ('poisson', PoissonRegressor(max_iter=1000))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "44ddb82d-18a4-409f-9d51-3780ee75cebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_poisson_cv = RandomizedSearchCV(\n",
    "    estimator=vanilla_poisson_model,\n",
    "    param_distributions={\n",
    "        'poisson__alpha': stats.uniform(0, 3),\n",
    "    },\n",
    "    cv=gkf.split(X_train, y_train, grouper_train),\n",
    "    n_iter=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "8e02e666-b95c-4242-8455-7043f03c1e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=<generator object _BaseKFold.split at 0x7f7171a1af50>,\n",
       "                   estimator=Pipeline(steps=[('transform',\n",
       "                                              ColumnTransformer(transformers=[('categoricals',\n",
       "                                                                               OneHotEncoder(drop=['Unknown',\n",
       "                                                                                                   'unknown',\n",
       "                                                                                                   1]),\n",
       "                                                                               ['bike_facs',\n",
       "                                                                                'fclass',\n",
       "                                                                                'fc_draft']),\n",
       "                                                                              ('standard_scale',\n",
       "                                                                               StandardScaler(),\n",
       "                                                                               ['speed',\n",
       "                                                                                'slope',\n",
       "                                                                                'near_univ_miles',\n",
       "                                                                                'near_large_univ_miles',\n",
       "                                                                                'strava_commute_ad...\n",
       "                                                                                'pctbiketowork_q',\n",
       "                                                                                'pctatleastbachelors_q',\n",
       "                                                                                'pctnoveh_q',\n",
       "                                                                                'popdensitysqmi_h',\n",
       "                                                                                'hshlddensitysqmi_h',\n",
       "                                                                                'empnum_density_h',\n",
       "                                                                                'pctwhite_h',\n",
       "                                                                                'pctbiketowork_h',\n",
       "                                                                                'pctatleastbachelors_h',\n",
       "                                                                                'pctnoveh_h'])])),\n",
       "                                             ('poisson',\n",
       "                                              PoissonRegressor(max_iter=1000))]),\n",
       "                   n_iter=25,\n",
       "                   param_distributions={'poisson__alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f715c90d5d0>})"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vanilla_poisson_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "70d2d0ad-9a97-4bf0-9f1a-567b3e13dcd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'in_sample_rmse': 186.65047464211733, 'out_sample_rmse': 320.42087239595185, 'model': Pipeline(steps=[('transform',\n",
      "                 ColumnTransformer(transformers=[('categoricals',\n",
      "                                                  OneHotEncoder(drop=['Unknown',\n",
      "                                                                      'unknown',\n",
      "                                                                      1]),\n",
      "                                                  ['bike_facs', 'fclass',\n",
      "                                                   'fc_draft']),\n",
      "                                                 ('standard_scale',\n",
      "                                                  StandardScaler(),\n",
      "                                                  ['speed', 'slope',\n",
      "                                                   'near_univ_miles',\n",
      "                                                   'near_large_univ_miles',\n",
      "                                                   'strava_commute_adb',\n",
      "                                                   'strava_leisure_adb',\n",
      "                                                   'strava_average_speed',\n",
      "                                                   'strava_leisure_pct',\n",
      "                                                   'popdensitysqm...\n",
      "                                                   'pctatleastbachelors_t',\n",
      "                                                   'pctnoveh_t',\n",
      "                                                   'popdensitysqmi_q',\n",
      "                                                   'hshlddensitysqmi_q',\n",
      "                                                   'empnum_density_q',\n",
      "                                                   'pctwhite_q',\n",
      "                                                   'pctbiketowork_q',\n",
      "                                                   'pctatleastbachelors_q',\n",
      "                                                   'pctnoveh_q',\n",
      "                                                   'popdensitysqmi_h',\n",
      "                                                   'hshlddensitysqmi_h',\n",
      "                                                   'empnum_density_h',\n",
      "                                                   'pctwhite_h',\n",
      "                                                   'pctbiketowork_h',\n",
      "                                                   'pctatleastbachelors_h',\n",
      "                                                   'pctnoveh_h'])])),\n",
      "                ('poisson',\n",
      "                 PoissonRegressor(alpha=2.814905615512658, max_iter=1000))])}\n"
     ]
    }
   ],
   "source": [
    "model_results['vanilla_poisson'] = evaluate_model(vanilla_poisson_cv.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ed096d-4327-4ec9-810f-6715c1ff14c4",
   "metadata": {},
   "source": [
    "Yikes, the out-of-sample RMSE is horrible! Let's try a tree-based model, then we'll try some interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a949e332-355c-46a8-848d-e376c81b7546",
   "metadata": {},
   "source": [
    "## 2c. Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7861df9b-b40e-4a65-81b7-47db8a18da0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu110.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m103"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
